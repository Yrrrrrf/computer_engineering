{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximation\n",
    "\n",
    "Is the process of **finding a function that is close to a given dataset**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "\n",
    "Returns a linear function in the form of $y = mx + b$ that best fits the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(x, y) -> Callable:\n",
    "    \"\"\"\n",
    "    Interpolate the data (x, y)\n",
    "\n",
    "    :param x: the x values\n",
    "    :param y: the y values\n",
    "    :return: the linear regression function in the form y = mx + b\n",
    "    \"\"\"\n",
    "    # ! return np.poly1d(np.polyfit(x, y, 1))  # but we won't use this because wi'll implement it ourselves\n",
    "    x_mean = np.mean(x)\n",
    "    y_mean = np.mean(y)\n",
    "    # cov = np.mean(x * y) - x_mean * y_mean  # covariance\n",
    "    # m = cov / np.var(x)  # slope\n",
    "    m = (np.mean(x * y) - x_mean * y_mean) / np.var(x)  # slope\n",
    "    b = y_mean - m * x_mean  # y-intercept\n",
    "    print(f'y = {m}x + {b}')\n",
    "    return lambda x: m * x + b"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Regression\n",
    "\n",
    "Returns an exponential function in the form of $y = a\\cdot m^x$ that best fits the given dataset.\n",
    "\n",
    "Where $a = e^b$ is the y-intercept and $m$ is the growth rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_regression(x, y) -> Callable:\n",
    "    \"\"\"\n",
    "    Interpolate the data (x, y)\n",
    "\n",
    "    :param x: the x values\n",
    "    :param y: the y values\n",
    "    :return: the exponential regression function in the form y = a * e^(bx)\n",
    "    \"\"\"\n",
    "    # ! return np.exp(np.polyfit(np.log(x), y, 1, full=True))  # but we won't use this because wi'll implement it ourselves\n",
    "    y = np.log(y)  # we need to take the log of 'y' because we want to find the slope of the log of 'y'\n",
    "    x_mean = np.mean(x)\n",
    "    y_mean = np.mean(y)\n",
    "    m = (np.mean(x * y) - x_mean * y_mean) / np.var(x)  # slope\n",
    "    b = y_mean - m * x_mean  # y-intercept\n",
    "    print(f'y = {np.exp(b)}e^{m}x')  # we need to take the exponential of 'b' because we took the log of 'y'\n",
    "    return lambda x: np.exp(m * x + b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power Regression\n",
    "\n",
    "Returns a power function in the form of $y = ax^b$ that best fits the given dataset.\n",
    "\n",
    "Where $a = e^b$ is the y-intercept.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_regression(x, y) -> Callable:\n",
    "    \"\"\"\n",
    "    Interpolate the data (x, y)\n",
    "\n",
    "    :param x: the x values\n",
    "    :param y: the y values\n",
    "    :return: the power regression function\n",
    "    \"\"\"\n",
    "    # ! return np.poly1d(np.polyfit(np.log(x), np.log(y), 1, full=True))  # but we won't use this because wi'll implement it ourselves\n",
    "    x = np.log(x)\n",
    "    y = np.log(y)\n",
    "    x_mean = np.mean(x)\n",
    "    y_mean = np.mean(y)\n",
    "    # cov = np.mean(x * y) - x_mean * y_mean  # covariance\n",
    "    # m = cov / np.var(x)  # slope\n",
    "    m = (np.mean(x * y) - x_mean * y_mean) / np.var(x)  # slope\n",
    "    b = y_mean - m * x_mean  # y-intercept\n",
    "    print(f'y = {np.exp(b)}x^{m}')  # we need to take the exponential of 'b' because we took the log of 'y'\n",
    "    return lambda x: np.exp(m * np.log(x) + b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Regression (curve fitting process)\n",
    "\n",
    "Is a generalization of linear regression that fits a polynomial function of degree $n$ to the given dataset.\n",
    "\n",
    "It use a variation of the polynomial function in the form of $y =\\Sigma {a_nx^n} = a_0 + a_1x + a_2x^2 + ... + a_nx^n$. Where $a_0$ is the y-intercept and $a_1$ is the slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_regression(x, y, degree: int = 2) -> Callable:\n",
    "    \"\"\"\n",
    "    Also known as Curve Fitting process\n",
    "    Interpolate the data (x, y)\n",
    "\n",
    "    :param x: the x values\n",
    "    :param y: the y values\n",
    "    :return: the polynomial regression function in the form y = ax^2 + bx + c\n",
    "    \"\"\"\n",
    "    # ! return np.poly1d(np.polyfit(x, y, degree))  # but we won't use this because wi'll implement it ourselves\n",
    "    A = np.zeros((degree + 1, degree + 1))  # degree+1 square matrix\n",
    "    for row in range(degree + 1):\n",
    "        for column in range(degree + 1): \n",
    "            A[row][column] = np.sum(x ** (row + column))\n",
    "    # print(f'A = {A}')\n",
    "    b = np.zeros(degree + 1)  # degree+1 column vector (results)\n",
    "    for row in range(degree + 1):\n",
    "        b[row] = np.sum((x ** row) * y)\n",
    "    # print(f'b = {b}')\n",
    "    x = np.linalg.solve(A, b)  # A * x = b => x = A^-1 * b\n",
    "    # print(f'x = {x}')\n",
    "    print(f'y = ', end='')\n",
    "    for i in range(degree + 1):\n",
    "        print(f'{x[i]:.4f}x^{i}', end='') if i == degree else print(f'{x[i]:.4f}x^{i} + ', end='')\n",
    "        # print(f'{x[i]:}x^{i}', end='') if i == degree else print(f'{x[i]:}x^{i} + ', end='')\n",
    "    print()  # new line\n",
    "    return lambda x: np.sum([x ** i * x[i] for i in range(degree + 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Create some data.\n",
    "    # x = np.linspace(0, 10, 10)\n",
    "    # y = np.linspace(1, 21, 11)\n",
    "    x = np.arange(1, 6)\n",
    "    y = np.array([0.5, 1.7, 3.4, 5.7, 8.4])\n",
    "\n",
    "    print(f'Linear Regression: {linear_regression(x, y)}')\n",
    "    print(f'Polynomial Regression: {polynomial_regression(x, y, degree=10)}')\n",
    "    print(f'Exponential Regression: {exponential_regression(x, y)}')\n",
    "    print(f'Power Regression: {power_regression(x, y)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "90e9cecf0ab6516382938111031b3a23db288579fe2d09bae4330be5540f9898"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
